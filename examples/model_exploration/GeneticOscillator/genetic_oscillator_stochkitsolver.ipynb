{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import gillespy2\n",
    "from gillespy2.solvers.stochkit import StochKitSolver\n",
    "from tsfresh.feature_extraction.settings import MinimalFCParameters\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from dask.distributed import Client\n",
    "os.environ[\"STOCHKIT_HOME\"] = '/home/jovyan/StochKit'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_doc = gillespy2.StochMLDocument.from_file(\"vilar_oscillator.xml\")\n",
    "vilar_model = model_doc.to_model(\"Vilar\")\n",
    "vilar_model.tspan = np.linspace(0, 100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define simulator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_parameters(params, model):\n",
    "    \"\"\" params - array, needs to have the same order as model.listOfParameters \"\"\"\n",
    "    for e, (pname, p) in enumerate(model.listOfParameters.items()):\n",
    "        model.get_parameter(pname).set_expression(params[e])\n",
    "    return model\n",
    "\n",
    "# Here we use gillespy2 numpy solver, so performance will be quite slow for this model\n",
    "def simulator(params, model):\n",
    "    \n",
    "    from gillespy2.solvers.numpy.ssa_solver import MaxStateReached\n",
    "    from sciope.stochmet.stochmet import EventFired\n",
    "    \n",
    "    model_update = set_model_parameters(params, model)\n",
    "    num_trajectories = 1 #TODO: howto handle ensembles\n",
    "\n",
    "    res = model_update.run(solver=StochKitSolver, show_labels=False, number_of_trajectories=num_trajectories)\n",
    "    tot_res = res[0][:,1:] #should not contain timepoints\n",
    "    \n",
    "    return np.array(tot_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameter sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_param = np.array(list(vilar_model.listOfParameters.items()))[:,1]\n",
    "bound = []\n",
    "for exp in default_param:\n",
    "    bound.append(float(exp.expression))\n",
    "    \n",
    "bound = np.array(bound)\n",
    "\n",
    "class Sampler():\n",
    "    \n",
    "    def __init__(self, min_, max_):\n",
    "        self.name = 'Uniform'\n",
    "        self.min_ = min_\n",
    "        self.max_ = max_\n",
    "        self.dim = len(max_)\n",
    "    \n",
    "    def generate(self, n_points):\n",
    "        points = np.random.uniform(self.min_, self.max_, (n_points, self.dim))\n",
    "        return points\n",
    "\n",
    "sampler = Sampler(min_=bound*0.1, max_=bound*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start local cluster using dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Client()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate StochMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sciope.stochmet.stochmet import StochMET\n",
    "\n",
    "#Arg: \"model\" enables us the change which model to be used\n",
    "simulator2 = lambda x : simulator(x, model=vilar_model)\n",
    "\n",
    "#lets use this set of features:\n",
    "default_fc_params = {'mean': None,\n",
    "                     'variance': None,\n",
    "                     'skewness': None,\n",
    "     'agg_autocorrelation': [{'f_agg': 'mean', 'maxlag': 5},\n",
    " {'f_agg': 'median', 'maxlag': 5},\n",
    " {'f_agg': 'var', 'maxlag': 5}]}\n",
    "\n",
    "\n",
    "met = StochMET(simulator=simulator2, sampler=sampler, features=default_fc_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run parameter sweep (will persist and running in background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vilar_model.listOfSpecies.keys())\n",
    "\n",
    "#Lets extract features for only 'Ma', 'Mr', 'C', 'A' and 'R'\n",
    "idx_species = [2,5,6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met.compute(n_points=100, n_species=idx_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the result\n",
    "Here we will explore parameter points expressed in feature space using a dimension reduction method. User can interact with points and label points according to different model behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First lets add some appropiate information about the model and features for interative purposes\n",
    "met.data.configurations['listOfParameters'] = list(vilar_model.listOfParameters.keys())\n",
    "met.data.configurations['listOfSpecies'] = list(vilar_model.listOfSpecies.keys())\n",
    "met.data.configurations['listOfSummaries'] = met.summaries.features\n",
    "met.data.configurations['timepoints'] = vilar_model.tspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Here we use UMAP for dimension reduction and collect the data from persited storage\n",
    "met.explore(dr_method='umap', from_distributed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once a few points has been added we can use Semi-supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sciope.models.label_propagation import LPModel\n",
    "#here lets use the dimension reduction embedding as input data\n",
    "data = met.dr_model.embedding_\n",
    "\n",
    "model_lp = LPModel()\n",
    "#train using basinhopping\n",
    "model_lp.train(data, met.data.user_labels, min_=0.01, max_=10, niter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to vislualize the result we will map the label distribution to the user_labels (will enable us to see the LP model \n",
    "# output when using \"explore\")\n",
    "\n",
    "user_labels = np.copy(met.data.user_labels)\n",
    "met.data.user_labels = model_lp.model.label_distributions_[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "met.explore(dr_method='umap', from_distributed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met.data.user_labels = user_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
